{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules using Apriori and FP Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2016 Everaldo Aguiar & Reid Johnson\n",
    "#\n",
    "# Modified from:\n",
    "# Marcel Caraciolo (https://gist.github.com/marcelcaraciolo/1423287)\n",
    "#\n",
    "# Functions to compute and extract association rules from a given frequent itemset \n",
    "# generated by the Apriori algorithm.\n",
    "#\n",
    "# The Apriori algorithm is defined by Agrawal and Srikant in:\n",
    "# Fast algorithms for mining association rules\n",
    "# Proc. 20th int. conf. very large data bases, VLDB. Vol. 1215. 1994\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(filename):\n",
    "    '''Loads an example of market basket transactions from a provided csv file.\n",
    "\n",
    "    Returns: A list (database) of lists (transactions). Each element of a transaction is \n",
    "    an item.\n",
    "    '''\n",
    "\n",
    "    with open(filename,'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"')\n",
    "        data = [data for data in data_iter]\n",
    "        data_array = np.asarray(data)\n",
    "        \n",
    "    return data_array\n",
    "\n",
    "def apriori(dataset, min_support=0.5, verbose=False):\n",
    "    \"\"\"Implements the Apriori algorithm.\n",
    "\n",
    "    The Apriori algorithm will iteratively generate new candidate \n",
    "    k-itemsets using the frequent (k-1)-itemsets found in the previous \n",
    "    iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] R. Agrawal, R. Srikant, \"Fast Algorithms for Mining Association \n",
    "           Rules\", 1994.\n",
    "\n",
    "    \"\"\"\n",
    "    C1 = create_candidates(dataset)\n",
    "    D = list(map(set, dataset))\n",
    "    F1, support_data = support_prune(D, C1, min_support, verbose=False) # prune candidate 1-itemsets\n",
    "    F = [F1] # list of frequent itemsets; initialized to frequent 1-itemsets\n",
    "    k = 2 # the itemset cardinality\n",
    "    while (len(F[k - 2]) > 0):\n",
    "        Ck = apriori_gen(F[k-2], k) # generate candidate itemsets\n",
    "        Fk, supK = support_prune(D, Ck, min_support) # prune candidate itemsets\n",
    "        support_data.update(supK) # update the support counts to reflect pruning\n",
    "        F.append(Fk) # add the pruned candidate itemsets to the list of frequent itemsets\n",
    "        k += 1\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the frequent itemsets.\n",
    "        for kset in F:\n",
    "            for item in kset:\n",
    "                print(\"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join(str(i) + \", \" for i in iter(item)).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  sup = \" + str(round(support_data[item], 3)))\n",
    "\n",
    "    return F, support_data\n",
    "\n",
    "def create_candidates(dataset, verbose=False):\n",
    "    \"\"\"Creates a list of candidate 1-itemsets from a list of transactions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The list of candidate itemsets (c1) passed as a frozenset (a set that is \n",
    "    immutable and hashable).\n",
    "    \"\"\"\n",
    "    c1 = [] # list of all items in the database of transactions\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the candidate items.\n",
    "        print(\"\" \\\n",
    "            + \"{\" \\\n",
    "            + \"\".join(str(i[0]) + \", \" for i in iter(c1)).rstrip(', ') \\\n",
    "            + \"}\")\n",
    "\n",
    "    # Map c1 to a frozenset because it will be the key of a dictionary.\n",
    "    return list(map(frozenset, c1))\n",
    "\n",
    "def support_prune(dataset, candidates, min_support, verbose=False):\n",
    "    \"\"\"Returns all candidate itemsets that meet a minimum support threshold.\n",
    "\n",
    "    By the apriori principle, if an itemset is frequent, then all of its \n",
    "    subsets must also be frequent. As a result, we can perform support-based \n",
    "    pruning to systematically control the exponential growth of candidate \n",
    "    itemsets. Thus, itemsets that do not meet the minimum support level are \n",
    "    pruned from the input list of itemsets (dataset).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    candidates : frozenset\n",
    "        The list of candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "    \"\"\"\n",
    "    sscnt = {} # set for support counts\n",
    "    for tid in dataset:\n",
    "        for can in candidates:\n",
    "            if can.issubset(tid):\n",
    "                sscnt.setdefault(can, 0)\n",
    "                sscnt[can] += 1\n",
    "\n",
    "    num_items = float(len(dataset)) # total number of transactions in the dataset\n",
    "    retlist = [] # array for unpruned itemsets\n",
    "    support_data = {} # set for support data for corresponding itemsets\n",
    "    for key in sscnt:\n",
    "        # Calculate the support of itemset key.\n",
    "        support = sscnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "\n",
    "    # Print a list of the pruned itemsets.\n",
    "    if verbose:\n",
    "        for kset in retlist:\n",
    "            for item in kset:\n",
    "                print(\"{\" + str(item) + \"}\")\n",
    "        print(\"\")\n",
    "        for key in sscnt:\n",
    "            print(\"\" \\\n",
    "                + \"{\" \\\n",
    "                + \"\".join([str(i) + \", \" for i in iter(key)]).rstrip(', ') \\\n",
    "                + \"}\" \\\n",
    "                + \":  sup = \" + str(support_data[key]))\n",
    "\n",
    "    return retlist, support_data\n",
    "\n",
    "def apriori_gen(freq_sets, k):\n",
    "    \"\"\"Generates candidate itemsets (via the F_k-1 x F_k-1 method).\n",
    "\n",
    "    This operation generates new candidate k-itemsets based on the frequent \n",
    "    (k-1)-itemsets found in the previous iteration. The candidate generation \n",
    "    procedure merges a pair of frequent (k-1)-itemsets only if their first k-2 \n",
    "    items are identical.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_sets : list\n",
    "        The list of frequent (k-1)-itemsets.\n",
    "\n",
    "    k : integer\n",
    "        The cardinality of the current itemsets being evaluated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of merged frequent itemsets.\n",
    "    \"\"\"\n",
    "    retList = [] # list of merged frequent itemsets\n",
    "    lenLk = len(freq_sets) # number of frequent itemsets\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            a=list(freq_sets[i])\n",
    "            b=list(freq_sets[j])\n",
    "            a.sort()\n",
    "            b.sort()\n",
    "            F1 = a[:k-2] # first k-2 items of freq_sets[i]\n",
    "            F2 = b[:k-2] # first k-2 items of freq_sets[j]\n",
    "\n",
    "            if F1 == F2: # if the first k-2 items are identical\n",
    "                # Merge the frequent itemsets.\n",
    "                retList.append(freq_sets[i] | freq_sets[j])\n",
    "\n",
    "    return retList\n",
    "\n",
    "def rules_from_conseq(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Generates a set of candidate rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "    m = len(H[0])\n",
    "    if m == 1:\n",
    "        Hmp1 = calc_confidence(freq_set, H, support_data, rules, min_confidence, verbose)\n",
    "    if (len(freq_set) > (m+1)):\n",
    "        Hmp1 = apriori_gen(H, m+1) # generate candidate itemsets\n",
    "        Hmp1 = calc_confidence(freq_set, Hmp1, support_data, rules, min_confidence, verbose)\n",
    "        if len(Hmp1) > 1:\n",
    "            # If there are candidate rules above the minimum confidence \n",
    "            # threshold, recurse on the list of these candidate rules.\n",
    "            rules_from_conseq(freq_set, Hmp1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "def calc_confidence(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Evaluates the generated rules.\n",
    "\n",
    "    One measurement for quantifying the goodness of association rules is \n",
    "    confidence. The confidence for a rule 'P implies H' (P -> H) is defined as \n",
    "    the support for P and H divided by the support for P \n",
    "    (support (P|H) / support(P)), where the | symbol denotes the set union \n",
    "    (thus P|H means all the items in set P or in set H).\n",
    "\n",
    "    To calculate the confidence, we iterate through the frequent itemsets and \n",
    "    associated support data. For each frequent itemset, we divide the support \n",
    "    of the itemset by the support of the antecedent (left-hand-side of the \n",
    "    rule).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pruned_H : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    pruned_H = [] # list of candidate rules above the minimum confidence threshold\n",
    "    for conseq in H: # iterate over the frequent itemsets\n",
    "        conf = support_data[freq_set] / support_data[freq_set - conseq]\n",
    "        if conf >= min_confidence:\n",
    "            rules.append((freq_set - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(freq_set-conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \" ---> \" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  conf = \" + str(round(conf, 3)) \\\n",
    "                    + \", sup = \" + str(round(support_data[freq_set], 3)))\n",
    "\n",
    "    return pruned_H\n",
    "\n",
    "def generate_rules(F, support_data, min_confidence=0.5, verbose=True):\n",
    "    \"\"\"Generates a set of candidate rules from a list of frequent itemsets.\n",
    "\n",
    "    For each frequent itemset, we calculate the confidence of using a\n",
    "    particular item as the rule consequent (right-hand-side of the rule). By \n",
    "    testing and merging the remaining rules, we recursively create a list of \n",
    "    pruned rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : list\n",
    "        A list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The corresponding support data for the frequent itemsets (L).\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rules : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(F)):\n",
    "        for freq_set in F[i]:\n",
    "            H1 = [frozenset([itemset]) for itemset in freq_set]\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "            else:\n",
    "                calc_confidence(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Number</th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>Offense Description</th>\n",
       "      <th>District</th>\n",
       "      <th>Reporting Area</th>\n",
       "      <th>Shooting</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Hour</th>\n",
       "      <th>UCR Offense Level</th>\n",
       "      <th>Street</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Is Dark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I192060182</td>\n",
       "      <td>Motor Vehicle Accident Response</td>\n",
       "      <td>M/V - LEAVING SCENE - PROPERTY DAMAGE</td>\n",
       "      <td>South Boston</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-02 21:59:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>SLEEPER ST</td>\n",
       "      <td>42.352175</td>\n",
       "      <td>-71.049134</td>\n",
       "      <td>(42.35217524, -71.04913425)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I192060181</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>ASSAULT SIMPLE - BATTERY</td>\n",
       "      <td>South End</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-02 21:15:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>E BROOKLINE ST</td>\n",
       "      <td>42.338696</td>\n",
       "      <td>-71.071399</td>\n",
       "      <td>(42.33869635, -71.07139879)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I192060181</td>\n",
       "      <td>Other</td>\n",
       "      <td>INTIMIDATING WITNESS</td>\n",
       "      <td>South End</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-02 21:15:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>E BROOKLINE ST</td>\n",
       "      <td>42.338696</td>\n",
       "      <td>-71.071399</td>\n",
       "      <td>(42.33869635, -71.07139879)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I192060180</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>ASSAULT SIMPLE - BATTERY</td>\n",
       "      <td>Mattapan</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-02 20:44:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>STANDISH ST</td>\n",
       "      <td>42.295977</td>\n",
       "      <td>-71.079340</td>\n",
       "      <td>(42.29597658, -71.07933990)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I192060179</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>VANDALISM</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-02 20:51:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>BEACON ST</td>\n",
       "      <td>42.336267</td>\n",
       "      <td>-71.149503</td>\n",
       "      <td>(42.33626664, -71.14950271)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Incident Number                     Offense Type  \\\n",
       "0      I192060182  Motor Vehicle Accident Response   \n",
       "1      I192060181                   Simple Assault   \n",
       "2      I192060181                            Other   \n",
       "3      I192060180                   Simple Assault   \n",
       "4      I192060179                        Vandalism   \n",
       "\n",
       "                     Offense Description      District Reporting Area  \\\n",
       "0  M/V - LEAVING SCENE - PROPERTY DAMAGE  South Boston            206   \n",
       "1               ASSAULT SIMPLE - BATTERY     South End            905   \n",
       "2                   INTIMIDATING WITNESS     South End            905   \n",
       "3               ASSAULT SIMPLE - BATTERY      Mattapan            443   \n",
       "4                              VANDALISM      Brighton            790   \n",
       "\n",
       "   Shooting                 Date  Year  Month Day of Week  Hour  \\\n",
       "0         0  2019-08-02 21:59:00  2019      8      Friday    21   \n",
       "1         0  2019-08-02 21:15:00  2019      8      Friday    21   \n",
       "2         0  2019-08-02 21:15:00  2019      8      Friday    21   \n",
       "3         0  2019-08-02 20:44:00  2019      8      Friday    20   \n",
       "4         0  2019-08-02 20:51:00  2019      8      Friday    20   \n",
       "\n",
       "  UCR Offense Level          Street   Latitude  Longitude  \\\n",
       "0        Part Three      SLEEPER ST  42.352175 -71.049134   \n",
       "1          Part Two  E BROOKLINE ST  42.338696 -71.071399   \n",
       "2        Part Three  E BROOKLINE ST  42.338696 -71.071399   \n",
       "3          Part Two     STANDISH ST  42.295977 -71.079340   \n",
       "4          Part Two       BEACON ST  42.336267 -71.149503   \n",
       "\n",
       "                   Coordinates  Is Dark  \n",
       "0  (42.35217524, -71.04913425)        1  \n",
       "1  (42.33869635, -71.07139879)        1  \n",
       "2  (42.33869635, -71.07139879)        1  \n",
       "3  (42.29597658, -71.07933990)        1  \n",
       "4  (42.33626664, -71.14950271)        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv('boston-crime.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Month from month number to month name\n",
    "import calendar\n",
    "d = dict(enumerate(calendar.month_abbr))\n",
    "df['Month'] = df['Month'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Shooting to have labels instead of 0,1\n",
    "df['Shooting'] = df['Shooting'].replace(1, 'Yes')\n",
    "df['Shooting'] = df['Shooting'].replace(0, 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification feature for time of day based on Hour\n",
    "df['Time'] = ''\n",
    "df.loc[(df['Hour'] > 20), 'Time'] = 'Night'\n",
    "df.loc[(df['Hour'] <= 5), 'Time'] = 'Night'\n",
    "df.loc[(df['Hour'] > 5) & (df['Hour'] <= 12), 'Time'] = 'Morning'\n",
    "df.loc[(df['Hour'] > 12) & (df['Hour'] <= 16), 'Time'] = 'Noon'\n",
    "df.loc[(df['Hour'] > 16) & (df['Hour'] <= 20), 'Time'] = 'Evening'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>District</th>\n",
       "      <th>Shooting</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>UCR Offense Level</th>\n",
       "      <th>Street</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motor Vehicle Accident Response</td>\n",
       "      <td>South Boston</td>\n",
       "      <td>No</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>SLEEPER ST</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>South End</td>\n",
       "      <td>No</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>E BROOKLINE ST</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>South End</td>\n",
       "      <td>No</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>E BROOKLINE ST</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Mattapan</td>\n",
       "      <td>No</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>STANDISH ST</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vandalism</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>No</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>BEACON ST</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Offense Type      District Shooting Month Day of Week  \\\n",
       "0  Motor Vehicle Accident Response  South Boston       No   Aug      Friday   \n",
       "1                   Simple Assault     South End       No   Aug      Friday   \n",
       "2                            Other     South End       No   Aug      Friday   \n",
       "3                   Simple Assault      Mattapan       No   Aug      Friday   \n",
       "4                        Vandalism      Brighton       No   Aug      Friday   \n",
       "\n",
       "  UCR Offense Level          Street     Time  \n",
       "0        Part Three      SLEEPER ST    Night  \n",
       "1          Part Two  E BROOKLINE ST    Night  \n",
       "2        Part Three  E BROOKLINE ST    Night  \n",
       "3          Part Two     STANDISH ST  Evening  \n",
       "4          Part Two       BEACON ST  Evening  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null values and unwanted features\n",
    "df.dropna()\n",
    "df = df.drop(['Incident Number', 'Offense Description', 'Reporting Area', 'Date',\n",
    "             'Year', 'Hour', 'Latitude', 'Longitude', 'Coordinates', 'Is Dark'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offense Type'] = df['Offense Type'].astype(str)\n",
    "df['District'] = df['District'].astype(str)\n",
    "df['Shooting'] = df['Shooting'].astype(str)\n",
    "df['Month'] = df['Month'].astype(str)\n",
    "df['Day of Week'] = df['Day of Week'].astype(str)\n",
    "df['UCR Offense Level'] = df['UCR Offense Level'].astype(str)\n",
    "df['Street'] = df['Street'].astype(str)\n",
    "df['Time'] = df['Time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.asarray(df[1:])\n",
    "D = list(map(set, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aug',\n",
       " 'E BROOKLINE ST',\n",
       " 'Friday',\n",
       " 'Night',\n",
       " 'No',\n",
       " 'Part Two',\n",
       " 'Simple Assault',\n",
       " 'South End'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10-1, A ST, ABBOT ST, ABBOTSFORD ST, ACADEMY CT, ADAIR RD, ADAMS ST, ADAMSON ST, ADDISON ST, ADELAIDE ST, AGASSIZ RD, AGNES AVE, AGUADILLA ST, AKRON ST, ALASKA ST, ALBAN ST, ALBANO ST, ALBANY ST, ALBEMARLE ST, ALBERT ST, ALBION ST, ALCOTT ST, ALDIE ST, ALDRICH ST, ALEXANDER ST, ALFORD ST, ALGONQUIN ST, ALLANDALE RD, ALLANDALE ST, ALLEGHANY ST, ALLERTON ST, ALLSTATE RD, ALLSTON ST, ALMONT ST, ALPHA RD, ALPHEUS RD, ALPINE ST, ALTHER ST, ALVARADO AVE, ALWIN ST, AMBROSE ST, AMERICAN LEGION HWY, AMES ST, AMES WAY, AMHERST ST, AMORY AVE, AMORY ST, ANAWAN AVE, ANDERSON ST, ANGELL ST, ANNABEL ST, ANNAPOLIS ST, ANNUNCIATION RD, ANSON ST, ANTWERP ST, APPLETON ST, ARBORVIEW RD, ARBUTUS ST, ARCADIA PARK, ARCADIA ST, ARCH ST, ARCHDALE RD, ARION ST, ARLINGTON ST, ARMANDINE ST, ARMINGTON ST, ASHFORD ST, ASHLEY ST, ASHMONT ST, ASHTON ST, ASPINWALL RD, ASTORIA ST, ATHELWOLD ST, ATHENS ST, ATHERTON ST, ATHOL ST, ATKINSON ST, ATLANTIC AVE, AUBURN ST, AUCKLAND ST, AUSTIN ST, AUTUMN ST, AVENUE DE LAFAYETTE, AVERY ST, AYLES RD, Aggravated Assault, Aircraft, Apr, Arson, Assembly or Gathering Violations, Aug, Auto Theft, Auto Theft Recovery, B ST, BABCOCK ST, BABSON ST, BACK ST, BADGER RD, BAGNAL ST, BAILEY ST, BAIRD ST, BAKER AVE, BAKER ST, BAKERSFIELD ST, BALFOUR ST, BALLOU AVE, BALSAM ST, BANFIELD AVE, BANTON ST, BARNES AVE, BARRY PARK, BARRY ST, BARTLETT PL, BARTLETT ST, BATESWELL RD, BAY STATE RD, BEACH POINT PL, BEACH ST, BEACON ST, BEARSE AVE, BEAUFORD LN, BEAVER ST, BEDFORD ST, BEECH GLEN ST, BEECH ST, BEECHCROFT ST, BEECHER ST, BEECHLAND, BEECHLAND CIR, BEECHLAND ST, BEETHOVEN ST, BELDEN ST, BELGRADE AVE, BELLEVUE ST, BELLFLOWER ST, BELLVISTA RD, BELMONT ST, BELVIDERE ST, BENNETT ST, BENNINGTON ST, BENT CT, BERKELEY ST, BERNARD ST, BERRY ST, BETHUNE WAY, BEVERLY ST, BEXLEY RD, BICKFORD AVE, BICKFORD ST, BICKNELL ST, BIGELOW ST, BINFORD ST, BINNEY ST, BIRCH ST, BIRCHWOOD ST, BIRD ST, BISHOP JOE L SMITH WAY, BISHOP ST, BISMARCK ST, BLACK FALCON AVE, BLACKFAN CIR, BLACKSTONE ST, BLACKWOOD ST, BLAGDEN ST, BLAKE ST, BLAKEMORE ST, BLAKEVILLE ST, BLANVON RD, BLOOMFIELD ST, BLOOMINGTON ST, BLOSSOM ST, BLUE HILL AVE, BLUE HILLS PKWY, BLUE LEDGE DR, BOARDMAN ST, BOLSTER ST, BOLTON ST, BOND ST, BORDER ST, BOSTON PL, BOSTON ST, BOURNESIDE ST, BOUTWELL ST, BOW ST, BOWDOIN AVE, BOWDOIN SQ, BOWDOIN ST, BOWER ST, BOWKER ST, BOWMAN ST, BOYD ST, BOYLSTON ST, BOYNTON ST, BRADEEN ST, BRADFIELD AVE, BRADFORD ST, BRADLEE ST, BRADSTON ST, BRAGDON ST, BRAINERD RD, BRAINTREE ST, BREED ST, BREMEN ST, BRENT ST, BRENTWOOD ST, BRIARCLIFF TER, BRIER RD, BRIGHTON AVE, BRIGHTON ST, BRINSLEY ST, BRINTON ST, BROAD ST, BROADWAY ST, BROCK ST, BROCKTON ST, BROMFIELD ST, BRONSDON ST, BROOK AVE, BROOKFIELD ST, BROOKLEDGE ST, BROOKLEY RD, BROOKLINE AVE, BROOKS ST, BROOKSDALE RD, BROOKSIDE AVE, BROOKWAY RD, BROOKWAY TER, BROWNING AVE, BRUNSWICK ST, BUCKINGHAM ST, BUCKNAM ST, BUNKER HILL ST, BURBANK ST, BURGESS ST, BURRELL ST, BURT ST, BUSINESS ST, BUTTONWOOD ST, BYNNER ST, BYRON ST, Ballistics, Brighton, C ST, CABOT ST, CALDER ST, CALDWELL ST, CALL ST, CALLENDER ST, CALUMET ST, CAMBRIDGE ST, CAMDEN ST, CAMELOT CT, CAMERON ST, CANAL ST, CANDOR PL, CANTERBURY ST, CAPEN ST, CARLISLE ST, CARLOS ST, CARMEN ST, CARMODY CT, CARNEY CT, CAROL CIR, CAROLINA AVE, CARROLTON RD, CARRUTH ST, CARSON ST, CARTER ST, CASPAR ST, CASSNET ST, CASTLEGATE RD, CASTLETON ST, CATAWBA ST, CATBIRD CT, CAUSEWAY ST, CAWFIELD ST, CEDAR GROVE ST, CEDAR ST, CEDRIC ST, CENTER PLZ, CENTERVALE PARK, CENTRAL AVE, CENTRAL SQ, CENTRAL ST, CENTRAL WHARF, CENTRE AVE, CENTRE ST, CERDAN AVE, CEYLON ST, CHAMBERLAIN ST, CHANDLER ST, CHANNEL CENTER ST, CHAPEL RD, CHARLAME ST, CHARLES PARK RD, CHARLES ST, CHARLES ST S, CHARLESGATE E, CHARLESGATE W, CHARLOTTE ST, CHARME AVE, CHARTER ST, CHASE ST, CHATHAM ST, CHAUNCY ST, CHELSEA ST, CHENEY ST, CHERITON RD, CHESBROUGH RD, CHESTER ST, CHESTERTON ST, CHESTNUT AVE, CHESTNUT HILL AVE, CHESTNUT RD, CHESTNUT ST, CHEVERUS RD, CHILCOTT PL, CHILD ST, CHINATOWN, CHINATOWN GATE, CHISWICK RD, CHRISTOPHER ST, CHURCH ST, CIRCUIT ST, CITY HALL AVE, CITY HALL PLZ, CITY SQ, CLAPP ST, CLARE AVE, CLAREMONT PARK, CLAREMONT ST, CLARENDON ST, CLARK ST, CLARKSON ST, CLARKWOOD ST, CLARON ST, CLAXTON ST, CLAYBOURNE ST, CLAYMOSS RD, CLEARWAY ST, CLEAVES ST, CLEMATIS ST, CLEMENTINE PARK, CLEVEMONT AVE, CLIFFMONT ST, CLIFFORD ST, CLIFTON ST, CLINTON PL, CLINTON ST, CLIVE ST, COBDEN ST, CODMAN PARK, CODMAN ST, COFFEY ST, COHASSET ST, COLBORNE RD, COLBURN ST, COLCHESTER ST, COLEMAN ST, COLERIDGE ST, COLEUS PARK, COLONEL MICHAEL J. MCDONO, COLONIAL AVE, COLORADO ST, COLUMBIA RD, COLUMBIA TER, COLUMBUS AVE, COLUMBUS SQ, COMMERCIAL ST, COMMERCIAL WHRF E, COMMERCIAL WHRF W, COMMONWEALTH AVE, COMO RD, CONCORD SQ, CONCORD ST, CONDOR ST, CONGRESS ST, CONISTON RD, CONSTANCE RD, CONWAY ST, COOK ST, COOLIDGE RD, COOPER ST, COPELAND PARK, COPELAND ST, COPLEY PL, CORBET ST, COREY RD, COREY ST, CORINTH ST, CORNELIA CT, CORNELL ST, CORNWALL ST, CORONA ST, CORWIN ST, COSTELLO CIR, COTTAGE RD, COTTAGE ST, COTTON ST, COURT SQ, COURT ST, COURTHOUSE WAY, COURTLAND RD, CRANMORE RD, CRAWFORD ST, CREIGHTON ST, CRESCENT, CRESCENT AVE, CRESTON ST, CRESTWAY RD, CRESTWOOD PARK, CRISPUS ATTUCKS PL, CROSS ST, CROSSMAN ST, CROWLEY-ROGERS WAY, CROWN POINT DR, CRYSTAL PL, CULBERT ST, CUMMINGS RD, CUMMINGS ST, CUMMINS HWY, CUNNINGHAM ST, CURTIS ST, CUSHING AVE, CUTTER RD, Charlestown, Commercial Burglary, Confidence Games, Counterfeiting, Criminal Harassment, D ST, DABNEY ST, DACIA ST, DACY ST, DAKOTA ST, DALE ST, DALESSIO CT, DALRYMPLE ST, DALTON ST, DANA AVE, DANIA ST, DANNY RD, DARTMOUTH PL, DARTMOUTH ST, DAVID G MUGAR WAY, DAVID ORTIZ DR, DAVISON ST, DAY ST, DEACONESS RD, DEARBORN ST, DECATUR ST, DECKARD ST, DEERING RD, DEGAUTIER WAY, DELFORD ST, DELHI ST, DENNIS ST, DENNISON ST, DENT ST, DERRY RD, DEVER ST, DEVON ST, DEVONSHIRE PL, DEVONSHIRE ST, DEWAR ST, DEWITT DR, DEXTER ST, DICKENS ST, DIETZ RD, DIMOCK ST, DISTRICT AVE, DITMUS CT, DITSON ST, DIX ST, DONALD RD, DONNYBROOK RD, DONWOOD TER, DORCHESTER AVE, DORCHESTER ST, DORIS ST, DOVE ST, DOWNER AVE, DOWNER CT, DR. MICHAEL GAVIN WAY, DRACUT ST, DRAPER ST, DRAYTON AVE, DRUMMOND ST, DRY DOCK AVE, DUBOIS ST, DUDLEY ST, DUDLEY TER, DUKE ST, DUMAS ST, DUNBAR AVE, DUNBOY ST, DUNCAN ST, DUNREATH ST, DUNSTABLE ST, DURHAM ST, DURNELL AVE, DUSTIN ST, DWINELL ST, Dec, Disorderly Conduct, Dorchester, Downtown, Drug Violation, E BERKELEY ST, E BROADWAY, E BROOKLINE ST, E CANTON ST, E CONCORD ST, E COTTAGE ST, E EAGLE ST, E EIGHTH ST, E FIFTH ST, E FIRST ST, E FOURTH ST, E INDIA ROW, E LENOX ST, E NEWTON ST, E NINTH ST, E SECOND ST, E SEVENTH ST, E SIXTH ST, E SPRINGFIELD ST, E ST, E THIRD ST, EAST ST, EASTBURN ST, EASTON ST, EASTWOOD CIRT, EDGE HILL ST, EDGEMERE RD, EDGERLY RD, EDGEWATER DR, EDGEWOOD ST, EDINBORO ST, EDISON GRN, EDNA RD, EDSON ST, EDWARDSON ST, EGREMONT RD, EIGHTH ST, ELDER ST, ELDON ST, ELIOT ST, ELIZABETH ST, ELKO ST, ELLERY ST, ELLINGTON ST, ELLIS ST, ELM HILL AVE, ELM HILL PARK, ELM ST, ELMER RD, ELMHURST ST, ELMIRA ST, ELMORE ST, ELTON ST, ELVEN RD, ELWYN RD, EMERALD CT, EMERY RD, EMMET ST, ENDICOTT ST, ENNEKING PKWY, ENTERPRISE ST, ERIE ST, ESMOND, ESMOND ST, ESSEX ST, ESTELLA ST, ESTRELLA ST, EUSTIS ST, EUTAW ST, EVANS ST, EVANS WAY, EVELYN ST, EVERETT AVE, EVERETT SQ, EVERETT ST, EVERGREEN ST, EVERTON ST, EXETER ST, Embezzlement, Evading Fare, Evening, Explosives, F ST, FAIRBANKS ST, FAIRFIELD ST, FAIRLAND ST, FAIRLAWN AVE, FAIRMOUNT AVE, FAIRMOUNT ST, FAIRVIEW AVE, FALCON ST, FALKLAND ST, FAN PIER BLVD, FANEUIL HALL MARKETPLACE, FANEUIL HALL SQ, FANEUIL ST, FARADAY ST, FARNHAM ST, FARQUHAR ST, FARRAGUT RD, FARRAR AVE, FARRIN ST, FARRINGTON AVE, FATHER FRANCIS J GILDAY S, FAULKNER CIR, FAULKNER ST, FAUNCE RD, FAVRE ST, FAWNDALE RD, FAYETTE ST, FAYSTON ST, FAYWOOD AVE, FEDERAL ST, FENELON ST, FENNO ST, FENWAY, FENWOOD RD, FERMOY HEIGHTS AVE, FERNALD TER, FERNBORO ST, FERNDALE ST, FERRIN ST, FESSENDEN ST, FIDELIS WAY, FIFIELD ST, FIRST AVE, FIRTH RD, FISHER AVE, FLAHERTY WAY, FLEET ST, FLORENCE ST, FLORIDA ST, FLOYD ST, FOLLEN ST, FOLSOM ST, FORBES ST, FORDHAM RD, FOREST HILLS ST, FOREST ST, FORSYTH ST, FORT AVE, FOSTER ST, FOTTLER RD, FOWLER ST, FOX ST, FRANCIS ST, FRANKFORT ST, FRANKLIN HILL AVE, FRANKLIN PARK RD, FRANKLIN ST, FRANKLIN TER, FRAWLEY ST, FRAZER ST, FREDERICK ST, FREEMAN AVE, FREEPORT ST, FREEPORT WAY, FREMONT ST, FRIEND ST, FRONTAGE RD, FROST AVE, FRUIT ST, FULDA ST, FULLER ST, FULTON ST, Feb, Fire Related Reports, Firearm Discovery, Firearm Violations, Fraud, Friday, GAINSBOROUGH ST, GALLIVAN BLVD, GANNETT ST, GARDNER ST, GARFIELD AVE, GARTLAND ST, GASTON ST, GAYLAND ST, GAYLORD ST, GEM AVE, GENE ST, GENERAL JOZEF PILSUDSKI W, GENERAL LAWRENCE J LOGA, GENERAL LAWRENCE J LOGAN , GENERAL WILLIAM H DEVINE , GENEVA AVE, GEORGE ST, GEORGETOWNE DR, GEORGETOWNE PL, GEORGIA ST, GERARD ST, GERMANIA ST, GIBSON ST, GILLETTE PARK, GILMER ST, GLADESIDE AVE, GLADSTONE ST, GLEASON ST, GLEN LN, GLEN RD, GLENBURNE ST, GLENCOE ST, GLENDALE ST, GLENELLEN RD, GLENVILLE AVE, GLENWAY ST, GLOUCESTER ST, GLOVER PL, GOLDSMITH ST, GOODALE RD, GORDON AVE, GORDON ST, GORHAM ST, GOVE ST, GRACE ST, GRAMPIAN WAY, GRANADA PARK, GRANFIELD AVE, GRANITE AVE, GRANT ST, GRASSMERE RD, GRAY ST, GRAYFIELD AVE, GREATON RD, GREEN ST, GREENBRIER ST, GREENBROOK RD, GREENDALE RD, GREENFIELD RD, GREENMOUNT ST, GREENOUGH AVE, GREENVILLE ST, GREENWICH PARK, GREENWICH ST, GREENWOOD AVE, GREENWOOD CIR, GREENWOOD ST, GRIMES ST, GROUSE ST, GROVE ST, GROVELAND ST, GROVENOR RD, GUEST ST, GUILD ST, GURNEY ST, H ST, HAGAR ST, HALBORN ST, HALE ST, HALF MOON ST, HALIFAX ST, HALLET ST, HALLOWELL ST, HALLRON ST, HAMILTON PL, HAMILTON ST, HAMMOND ST, HAMPDEN ST, HANCOCK ST, HANNON ST, HANO ST, HANOVER ST, HANSBOROUGH ST, HANSON ST, HARBOR POINT BLVD, HARBOR ST, HARBORSIDE DR, HARCOURT ST, HARLEM ST, HARLEY ST, HARMON ST, HAROLD PARK, HAROLD ST, HARRISHOF ST, HARRISON ARCHWAYS, HARRISON AVE, HARRISON AVE EXT, HARTFORD ST, HARTWELL ST, HARVARD AVE, HARVARD PL, HARVARD ST, HARVEST ST, HARWOOD ST, HASTINGS ST, HATHAWAY ST, HAVELOCK ST, HAVERFORD ST, HAVEY ST, HAVILAND ST, HAVRE ST, HAWLEY ST, HAWTHORNE PL, HAYDN ST, HAYES RD, HAYMARKET SQ, HAZLETON ST, HEATH ST, HEBRON ST, HECLA ST, HELEN ST, HELENA RD, HEMENWAY ST, HENDRY ST, HENRY STERLING SQ, HERALD ST, HERBERT ST, HEREFORD ST, HEWINS ST, HIAWATHA RD, HICHBORN ST, HIGH ST, HIGH VIEW AVE, HIGHCREST RD, HIGHCREST TER, HIGHLAND AVE, HIGHLAND ST, HILL TOP ST, HILLCREST ST, HILLIS RD, HILLSBORO RD, HILLSIDE ST, HOBSON ST, HOFFMAN ST, HOLBORN ST, HOLDEN ST, HOLIDAY ST, HOLLANDER ST, HOLLINGSWORTH ST, HOLMAN ST, HOLTON ST, HOLWORTHY ST, HOME INVASION, HOMES AVE, HOMESTEAD ST, HOOKER ST, HOOPER ST, HOPEDALE ST, HOPESTILL ST, HOPEWELL RD, HORACE ST, HORADAN WAY, HORAN WAY, HOSMER ST, HOWARD AVE, HOWE ST, HOWITT RD, HOWLAND ST, HOYT ST, HUDSON, HUDSON ST, HUMBOLDT AVE, HUMPHREYS ST, HUNNEWELL AVE, HUNTINGTON AVE, HUTCHINGS ST, HYDE PARK AVE, Harassment, Harbor Related Incidents, Homicide, Hyde Park, I ST, IDAHO ST, IFFLEY RD, INDEPENDENCE DR, INDIA ST, INDUSTRIAL DR, INTERVALE ST, INWOOD ST, IPSWICH ST, IRMA ST, IROQUOIS ST, IRVING ST, IRWIN AVE, ISLAND ST, ITASCA ST, Investigate Person, Investigate Property, JACKSON PL, JACOB ST, JAMAICAWAY, JEFFRIES ST, JEROME ST, JERSEY, JERSEY ST, JERSEY WAY, JETTE CT, JEWETT ST, JEWISH WAR VETERANS DR, JOHN ELIOT SQ, JOHN F. FITZGERALD SURFAC, JOHNSON TER, JOHNSTON RD, JOHNSWOOD RD, JOSEPH ST, JOSEPHINE ST, JOY ST, JUDGE ST, JULIAN ST, JULIETTE ST, JUNE ST, JUSTIN RD, Jamaice Plain, Jan, Jul, Jun, K ST, KEARSARGE AVE, KEEGAN ST, KELTON ST, KEMBLE ST, KENBERMA RD, KENILWORTH ST, KENNEBEC ST, KENNEY ST, KENRICK ST, KENSINGTON PARK, KENSINGTON ST, KENWOOD ST, KERWIN ST, KILBY ST, KILMARNOCK ST, KILSYTH RD, KIMBALL ST, KING ST, KINGBIRD RD, KINGSDALE ST, KINGSTON ST, KIRKWOOD RD, KITTREDGE ST, KNEELAND ST, KNIGHT ST, KOVEY RD, L ST, LAGRANGE ST, LAKE SHORE RD, LAKEVILLE RD, LAMARTINE ST, LAMBERT AVE, LANARK RD, LANCASTER ST, LANDING ST, LANDOR RD, LANE PARK, LANGDON ST, LANSDOWNE ST, LARCHMONT ST, LASELL ST, LATTIMORE CT, LAUREL ST, LAWRENCE AVE, LAWRENCE PL, LEDGEBROOK RD, LEE ST, LEEDSVILLE ST, LEGENDS WAY, LEICESTER ST, LENA TER, LENNON CT, LENOX ST, LEO M BIRMINGHAM PKWY, LEON ST, LEROY ST, LESHER ST, LESLIE ST, LESTON ST, LEVANT ST, LEWIS WHRF, LEWISTON ST, LEXINGTON AVE, LEXINGTON ST, LEYDEN ST, LEYLAND ST, LIBERTY DR, LINCOLN ST, LINDEN ST, LINDSEY ST, LINWOOD ST, LITHGOW ST, LIVERMORE ST, LIVINGSTONE ST, LNG-INBOUND, LOCHLAND RD, LOCHSTEAD AVE, LOMASNEY WAY, LONDON ST, LONG, LONG WHRF, LONGFELLOW PL, LONGFELLOW ST, LONGWOOD AVE, LONSDALE ST, LORENZO ST, LORETTE ST, LORING ST, LORNA RD, LORNE ST, LOTHROP ST, LOUIS TER, LOURDES AVE, LUBEC ST, LUCERNE ST, LUDLOW ST, LYNDHURST ST, LYON ST, Landlord/Tenant Disputes, Larceny, Larceny From Motor Vehicle, License Plate Related Incidents, License Violation, Liquor Violation, M ST, MADISON PARK CT, MADISON ST, MAFFA WAY, MAGAZINE ST, MAGNOLIA ST, MAIN ST, MALCOLM X BLVD, MALLET ST, MALLON RD, MALVERN ST, MALVERNA RD, MANCHESTER ST, MANILA AVE, MANLEY ST, MANN ST, MANNING ST, MANSUR ST, MANTHORNE RD, MAPLE ST, MAPLE TER, MAPLETON ST, MAPLEWOOD ST, MARBURY TER, MARCELLA ST, MARCY RD, MARDEN AVE, MARGARETTA DR, MARGINAL RD, MARGINAL ST, MARINA PARK DR, MARINE RD, MARION ST, MARIPOSA ST, MARK ST, MARKET ST, MARLBOROUGH ST, MARSHALL ST, MARSHFIELD ST, MARTIN LUTHER KING JR BLV, MARVIN ST, MARYKNOLL ST, MARYLAND ST, MASCOMA ST, MASCOT ST, MASON ST, MASSACHUSETTS AVE, MASSASOIT ST, MATCHETT ST, MATHER ST, MATTAPAN ST, MAVERICK, MAVERICK SQ, MAVERICK ST, MAXWELL ST, MAYFIELD ST, MAYHEW ST, MAYWOOD ST, MCBRIDE ST, MCGREEVEY WAY, MCKINLEY SQ, MCKONE ST, MCLELLAN ST, MCNULTY CT, MEADOWBANK AVE, MEDALLION AVE, MEDFORD ST, MELBOURNE ST, MELCHER ST, MELNEA CASS BLVD, MELVILLE AVE, MERCEDES VW, MERCER ST, MERCIER AVE, MERIDIAN ST, MERRILL ST, MERRIMAC ST, MESSINGER ST, METROPOLITAN AVE, MICHIGAN AVE, MIDDLE ST, MIDDLETON ST, MIDLAND ST, MILDRED AVE, MILFORD ST, MILK ST, MILLET ST, MILLS ST, MILLSTONE RD, MILTON AVE, MILTON ST, MINDEN ST, MINOT ST, MISSION PARK DR, MONADNOCK ST, MONMOUTH ST, MONSIGNOR ALBERT A. JACOB, MONSIGNOR DENNIS F O'CALL, MONSIGNOR JOHN J. O'DONNE, MONSIGNOR PATRICK J. LYDO, MONSIGNOR REYNOLDS WAY, MONTANA ST, MONTEBELLO RD, MONTELLO ST, MONTEREY AVE, MONTFERN AVE, MONTMORENCI AVE, MONTROSE ST, MONTVALE ST, MONTVIEW ST, MONUMENT ST, MOORE ST, MORA ST, MORAINE ST, MORELAND ST, MORRIS ST, MORROW RD, MORSE ST, MORTON ST, MORTON VILLAGE DR, MOSELEY ST, MOSSDALE RD, MOULTRIE ST, MOUNT CALVARY RD, MOUNT EVERETT ST, MOUNT HOOD RD, MOUNT HOPE ST, MOUNT IDA RD, MOUNT PLEASANT AVE, MOUNT PLEASANT ST, MOUNT VERNON ST, MOUNTAIN AVE, MOUNTFORT ST, MOZART ST, MULVEY ST, MUNROE ST, MURDOCK ST, MUSIC HALL PL, MYLES STANDISH RD, MYRICK ST, MYRTLE ST, MYRTLEBANK AVE, MYSTIC ST, Mar, Mattapan, May, Medical Assistance, Missing Person Located, Missing Person Reported, Monday, Morning, Motor Vehicle Accident Response, N BEACON ST, N BENNET ST, N FANEUIL HALL MARKETPLAC, N HARVARD ST, N MARGIN ST, N MEAD ST, N ST, N WASHINGTON ST, NAHANT AVE, NASHUA ST, NASSAU ST, NAVARRE ST, NAZING CT, NAZING ST, NECCO ST, NEEDHAM RD, NEILLIAN CRES, NELSON ST, NEPONSET AVE, NEPONSET VALLEY PKWY, NEVINS ST, NEW BEDFORD ST, NEW CHARDON ST, NEW ENGLAND AVE, NEW RUTHERFORD AVE, NEW ST, NEW SUDBURY ST, NEW WHITNEY ST, NEWBURG ST, NEWBURY ST, NEWHALL ST, NEWMARKET SQ, NIGHTINGALE ST, NINTH ST, NIRA AVE, NIXON ST, NORFOLK AVE, NORFOLK ST, NORMANDY ST, NORTH POINT DR, NORTH SQ, NORTH ST, NORTHAMPTON ST, NORTHDALE RD, NORTHERN AVE, NORTON ST, NORWAY PARK, NORWELL ST, NORWOOD ST, NOTRE DAME ST, NOTT ST, NOTTINGHAM ST, NOTTINGHILL RD, Night, No, Noon, Nov, O ST, O'MEARA CT, O'REILLY, OAK SQUARE AVE, OAK ST, OAK ST W, OAKLAND ST, OAKLEY ST, OAKMAN ST, OAKMERE ST, OAKWOOD ST, OCEAN VIEW DR, OGDEN ST, OLD COLONY AVE, OLD IRONSIDES WAY, OLD LANDING WAY, OLD MORTON ST, OLD RD, OLDFIELDS RD, OLEANDER ST, OLMSTEAD ST, OLNEY ST, OPHIR ST, ORANGE ST, ORCHARDFIELD ST, ORCHARDHILL RD, ORIENT AVE, ORKNEY RD, ORLANDO ST, ORLEANS ST, ORMOND ST, ORNE ST, ORTON-MAROTTA WAY, OSCEOLA ST, OSPREY WAY, OTIS PL, OUTLOOK RD, OVERLAND ST, OWENCROFT RD, OXFORD ST, Oct, Offenses Against Child / Family, Operating Under the Influence, Other, Other Burglary, P ST, PACIFIC ST, PAGE ST, PAINE ST, PALACE RD, PALMER ST, PARIS ST, PARK DR, PARK LN, PARK PLZ, PARK ST, PARK VIEW ST, PARKER HILL AVE, PARKER ST, PARKMAN ST, PARLEY AVE, PARLEY VALE, PARMELEE ST, PARSONS ST, PASADENA RD, PATTERSON ST, PATTERSON WAY, PAUL GORE ST, PAXTON ST, PAYSON AVE, PEACEVALE RD, PEARL ST, PEDDOCKS ISLAND, PEMBERTON SQ, PEMBROKE ST, PENINSULA PL, PENNIMAN RD, PERCIVAL ST, PERHAM ST, PERKINS ST, PERRIN ST, PERRY ST, PERSHING RD, PERTH ST, PETER PARLEY RD, PETERBOROUGH ST, PHILBRICK ST, PIEDMONT ST, PIERCE ST, PIERPONT RD, PILGRIM RD, PINCKNEY ST, PINE ST, PINEWOOD ST, PLANT CT, PLAYSTEAD RD, PLEASANT HILL AVE, PLEASANT ST, PLEASANTVIEW ST, POLK ST, POMFRET ST, POND ST, POPLAR ST, PORT NORFOLK ST, PORTER ST, PORTINA RD, PORTLAND ST, POST OFFIC, POST OFFICE SQ, POWELLTON RD, PRATT ST, PREBLE ST, PRENTISS ST, PRESCOTT ST, PRICE RD, PRINCE ST, PRINCETON ST, PRISCILLA RD, PROVIDENCE ST, PROVINCE ST, PUBLIC ALLEY NO 424, PUBLIC ALLEY NO. 433, PURCHASE ST, PUTNAM ST, Part One, Part Three, Part Two, Police Service Incidents, Prisoner Related Incidents, Property Found, Property Lost, Property Related Damage, Prostitution, QUEENSBERRY ST, QUINCY ST, QUINN WAY, QUINT AVE, RADCLIFFE RD, RADCLIFFE ST, RADFORD LN, RADNOR RD, RALDNE RD, RANDOLPH ST, RANELEGH RD, RANGELEY ST, RAVEN ST, RAYMOND ST, READING ST, READVILLE ST, RECTOR RD, REDDY AVE, REDLANDS RD, REEDSDALE ST, REGENT ST, REGINA RD, REGIS RD, REV RICHARD A BURKE ST, REVERE ST, REXFORD ST, REXHAME ST, RHOADES ST, RICHARD B. ROSS WAY, RICHARDSON ST, RICHFIELD ST, RICHMERE RD, RICHMOND ST, RIDGEWOOD ST, RIDLON RD, RILL ST, RING RD, RIPLEY RD, RITCHIE ST, RIVER ST, RIVERSIDE SQ, RIVERWAY, ROBESON ST, ROBINSON ST, ROBINWOOD AVE, ROCKDALE ST, ROCKINGHAM AVE, ROCKLAND ST, ROCKVALE CIR, ROCKVILLE PARK, ROCKWELL ST, ROGERS PARK AVE, ROLLINS ST, ROMSEY ST, RONAN ST, ROSEBERY RD, ROSECLAIR ST, ROSEDALE ST, ROSEWOOD ST, ROSLIN ST, ROSSELERIN RD, ROSSETER ST, ROSSMORE RD, ROSWELL ST, ROWE ST, ROWES WHRF, ROXANA ST, ROXBURY ST, ROXTON ST, ROYAL ST, ROYCE RD, RUGGLES ST, RUTHERFORD AVE, RUTHVEN ST, RUTLAND SQ, RUTLAND ST, RUXTON RD, Recovered Stolen Property, Residential Burglary, Restraining Order Violations, Robbery, Roxbury, S BREMEN ST, S HAMPTON ST, S HUNTINGTON AVE, S MUNROE TER, S SYDNEY ST, S WALTER ST, SACHEM ST, SAFFORD ST, SAINT ALPHONSUS ST, SAINT BOTOLPH ST, SAINT CHARLES ST, SAINT CYPRIANS PL, SAINT EDWARD RD, SAINT GEORGE, SAINT GEORGE ST, SAINT GERMAIN ST, SAINT GREGORY ST, SAINT JAMES AVE, SAINT JAMES ST, SAINT JOSEPH ST, SAINT LUKES RD, SAINT MARKS RD, SAINT ROSE ST, SAINT STEPHEN ST, SALEM ST, SALMAN ST, SAMUEL MORSE WAY, SAN JUAN ST, SANBORN AVE, SANFORD ST, SANGER ST, SANTUIT ST, SARATOGA ST, SARGENT ST, SAVANNAH AVE, SAVIN HILL AVE, SAVIN ST, SAXTON ST, SAYBROOK ST, SCHOOL ST, SCHREPEL PL, SCHROEDER PLZ, SCHUYLER ST, SEAPORT BLVD, SEARLE RD, SEAVER ST, SEGEL ST, SELDEN ST, SELKIRK RD, SEMINOLE ST, SEMONT RD, SENATOR BOLLING CIR, SENDERS CT, SHAFTER ST, SHANDON RD, SHANLEY ST, SHANNON ST, SHAWMUT AVE, SHEAFE ST, SHEFFIELD RD, SHEPTON ST, SHERIDAN ST, SHERRIN ST, SHETLAND ST, SHIRLEY ST, SIDLAW RD, SIERRA RD, SKYLINE RD, SLAYTON WAY, SLEEPER ST, SMITH ST, SNOWDEN WAY, SOLARIS RD, SOLDIERS FIELD RD, SOLEY ST, SONOMA ST, SOUTH ST, SOUTHAMPTON ST, SOUTHBAY, SOUTHERN AVE, SOUTHWICK ST, SPARHAWK ST, SPAULDING ST, SPEEDWAY AVE, SPEEDWELL ST, SPENCER ST, SPOFFORD RD, SPRAGUE ST, SPRING ST, SPRING VALLEY RD, STAFFORD ST, STANDARD ST, STANDISH ST, STANIFORD ST, STANLEY ST, STANTON ST, STANWOOD ST, STATE ST, STATION ST, STEARNS RD, STEDMAN ST, STELLMAN RD, STIMSON ST, STOCKTON ST, STONE TER, STONECREST RD, STONEHILL RD, STONEHURST ST, STOUGHTON ST, STRATFORD ST, STRATHCONA RD, STRATHMORE RD, STRATTON ST, STUART ST, STURBRIDGE ST, SUDAN ST, SUMMER ST, SUMMIT AVE, SUMMIT ST, SUMNER SQ, SUMNER ST, SUNNYSIDE ST, SUPPLE RD, SURREY ST, SUSANNA CT, SUTHERLAND RD, SUTTON ST, SWAN AVE, SWIFT ST, SYCAMORE ST, SYDNEY ST, SYMPHONY RD, Saturday, Search Warrants, Sep, Service, Simple Assault, South Boston, South End, Sunday, TACOMA ST, TALBOT AVE, TAUNTON AVE, TELEGRAPH ST, TEMPLE PL, TEMPLE ST, TENNIS RD, TERMINAL ST, TERRACE PL, TERRACE ST, THACHER ST, THATCHER ST, THEODORE ST, THETFORD AVE, THOMAS PARK, THOMAS ST, THOMPSON SQ, THOMPSON ST, THOMSON PL, THORNLEY ST, THURSTON ST, TIBBETT'S TOWN WAY, TICKNOR ST, TILESTON ST, TIVERTON RD, TOBIN RD, TONAWANDA ST, TOPALIAN ST, TOPEKA ST, TOPLIFF ST, TOVAR ST, TOWNSEND ST, TRAIN ST, TRANSPORTATION WAY, TRAVELER ST, TREMLETT ST, TREMONT ST, TRENTON ST, TRESCOTT ST, TRINITY TER, TROTTER CT, TRULL ST, TRUMAN PKWY, TUFTS ST, TURTLE POND PKWY, TUTTLE ST, TYLER ST, Thursday, Towed, Tuesday, UCC, UNDINE RD, UNION AVE, UNION PARK, UNION PARK ST, UNION ST, UNITY WAY, UPTON ST, VALLAR RD, VALLARO RD, VAN BRUNT ST, VAN WINKLE ST, VASSAR ST, VAUGHAN AVE, VERMONT ST, VERRILL ST, VERSHIRE ST, VESTA RD, VFW PKWY, VICTORIA ST, VICTORY RD, VILLAGE CT, VINAL ST, VINE AVE, VINE ST, VINSON ST, VIOLET ST, VISTA ST, Vandalism, Verbal Disputes, Violations, W BOUNDARY RD, W BROADWAY, W BROOKLINE ST, W CANTON ST, W CONCORD ST, W DEDHAM ST, W EAGLE ST, W EIGHTH ST, W FOURTH ST, W MAIN ST, W NEWTON ST, W NINTH ST, W PARK ST, W RUTLAND SQ, W SCHOOL ST, W SECOND ST, W SELDEN ST, W SEVENTH ST, W SPRINGFIELD ST, W THIRD ST, W TREMLETT ST, W WALNUT PARK, WABON ST, WAINWRIGHT ST, WAIT ST, WAKULLAH ST, WALDECK ST, WALDEMAR AVE, WALDEN ST, WALDREN RD, WALES ST, WALFORD WAY, WALK HILL ST, WALLINGFORD RD, WALNUT AVE, WALNUT PARK, WALNUT ST, WALTER ST, WALTHAM ST, WALWORTH ST, WARD ST, WARDMAN RD, WARNER ST, WARREN AVE, WARREN PL, WARREN ST, WARRENTON ST, WARWICK ST, WASHBURN ST, WASHINGTON ST, WATER ST, WAUMBECK ST, WAVERLY ST, WAYLAND ST, WAYNE ST, WEAVER WAY, WEBSTER ST, WELLES AVE, WELLINGTON HILL ST, WELLINGTON ST, WELLSMERE RD, WENDELLER ST, WENDOVER ST, WENONAH ST, WENTWORTH ST, WENTWORTH TER, WESLEYAN PL, WESSEX ST, WEST ST, WESTCOTT ST, WESTERN AVE, WESTFORD ST, WESTGATE RD, WESTGLOW ST, WESTINGHOUSE PLZ, WESTLAND AVE, WESTMINSTER CT, WESTMINSTER ST, WESTMINSTER TER, WESTMOOR RD, WESTMORE RD, WESTVIEW, WESTVIEW ST, WESTVIEW WAY, WESTVILLE ST, WESTVILLE TER, WESTWIND RD, WEYBOSSET ST, WHARF ST, WHEATLAND AVE, WHIPPLE AVE, WHITBY TER, WHITE ST, WHITFIELD ST, WHITMAN ST, WHITTEN ST, WIGGLESWORTH ST, WILBERT RD, WILBUR CT, WILCOCK ST, WILCOX RD, WILDWOOD ST, WILKINS PL, WILLIAM C KELLY SQ, WILLIAM F MCCLELLAN HWY, WILLIAM J DAY BLVD, WILLIAM T MORRISSEY BLVD, WILLIAMS AVE, WILLIAMS ST, WILLIS ST, WILLOW ST, WILLOWWOOD ST, WILMINGTON AVE, WILMORE ST, WILTON ST, WINDERMERE, WINDHAM RD, WINSHIP PL, WINSHIP ST, WINSLOW ST, WINSTON RD, WINTER PL, WINTER ST, WINTHROP ST, WISE ST, WITHINGTON ST, WOLFE ST, WOLLASTON TER, WOOD AVE, WOODBINE ST, WOODBOLE AVE, WOODBRIER RD, WOODCLIFF ST, WOODFORD ST, WOODGLEN RD, WOODHAVEN ST, WOODLAWN ST, WOODROW AVE, WOODRUFF WAY, WOODSIDE AVE, WOODSTOCK AVE, WOODVILLE ST, WOODWARD PARK ST, WOODWARD ST, WOOLSON ST, WORCESTER SQ, WORCESTER ST, WORDSWORTH ST, WORMWOOD ST, WORRELL ST, WORTHINGTON ST, WRENTHAM ST, WYMAN ST, WYOMING ST, WYVERN ST, Warrant Arrests, Wednesday, West Roxbury, YARMOUTH ST, YAWKEY WAY, Yes, ZAMORA ST, ZEIGLER ST, ZELLER ST, nan}\n"
     ]
    }
   ],
   "source": [
    "# Generate candidate itemsets\n",
    "C1 = create_candidates(df[:10000], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Feb}:  sup = 0.07\n",
      "{Nov}:  sup = 0.078\n",
      "{Jan}:  sup = 0.078\n",
      "{Oct}:  sup = 0.087\n",
      "{Saturday}:  sup = 0.14\n",
      "{Apr}:  sup = 0.078\n",
      "{Sep}:  sup = 0.088\n",
      "{Mar}:  sup = 0.078\n",
      "{May}:  sup = 0.089\n",
      "{Sunday}:  sup = 0.126\n",
      "{Jun}:  sup = 0.087\n",
      "{Dec}:  sup = 0.076\n",
      "{Wednesday}:  sup = 0.148\n",
      "{Noon}:  sup = 0.223\n",
      "{Tuesday}:  sup = 0.144\n",
      "{Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{Jamaice Plain}:  sup = 0.055\n",
      "{Investigate Person}:  sup = 0.062\n",
      "{Hyde Park}:  sup = 0.057\n",
      "{Dorchester}:  sup = 0.131\n",
      "{Thursday}:  sup = 0.147\n",
      "{Part One}:  sup = 0.179\n",
      "{Larceny}:  sup = 0.081\n",
      "{Roxbury}:  sup = 0.157\n",
      "{Morning}:  sup = 0.295\n",
      "{Monday}:  sup = 0.142\n",
      "{Jul}:  sup = 0.099\n",
      "{South Boston}:  sup = 0.074\n",
      "{Medical Assistance}:  sup = 0.083\n",
      "{Downtown}:  sup = 0.152\n",
      "{Brighton}:  sup = 0.063\n",
      "{Mattapan}:  sup = 0.115\n",
      "{Evening}:  sup = 0.23\n",
      "{Part Three}:  sup = 0.518\n",
      "{Other}:  sup = 0.06\n",
      "{South End}:  sup = 0.126\n",
      "{Simple Assault}:  sup = 0.052\n",
      "{Part Two}:  sup = 0.299\n",
      "{No}:  sup = 0.997\n",
      "{Night}:  sup = 0.253\n",
      "{Friday}:  sup = 0.153\n",
      "{Aug}:  sup = 0.093\n",
      "{Feb, No}:  sup = 0.069\n",
      "{Nov, No}:  sup = 0.078\n",
      "{No, Jan}:  sup = 0.078\n",
      "{Oct, No}:  sup = 0.086\n",
      "{Part Three, Saturday}:  sup = 0.074\n",
      "{Saturday, No}:  sup = 0.14\n",
      "{Part Three, Sunday}:  sup = 0.066\n",
      "{Apr, No}:  sup = 0.078\n",
      "{Sep, No}:  sup = 0.087\n",
      "{No, Mar}:  sup = 0.078\n",
      "{No, May}:  sup = 0.088\n",
      "{Part Three, Monday}:  sup = 0.073\n",
      "{Sunday, No}:  sup = 0.125\n",
      "{Jun, No}:  sup = 0.087\n",
      "{Part Three, Thursday}:  sup = 0.076\n",
      "{Wednesday, Part Three}:  sup = 0.076\n",
      "{Dec, No}:  sup = 0.076\n",
      "{Part Three, Noon}:  sup = 0.114\n",
      "{Part Two, Noon}:  sup = 0.068\n",
      "{Wednesday, No}:  sup = 0.148\n",
      "{No, Noon}:  sup = 0.223\n",
      "{Part Three, Jul}:  sup = 0.05\n",
      "{Part Three, Morning}:  sup = 0.163\n",
      "{Tuesday, No}:  sup = 0.144\n",
      "{Part Three, Tuesday}:  sup = 0.074\n",
      "{No, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{Part Three, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{No, Investigate Person}:  sup = 0.062\n",
      "{Part Three, Investigate Person}:  sup = 0.062\n",
      "{Jamaice Plain, No}:  sup = 0.054\n",
      "{Part Three, Roxbury}:  sup = 0.079\n",
      "{No, Hyde Park}:  sup = 0.056\n",
      "{No, Dorchester}:  sup = 0.131\n",
      "{Part Three, Dorchester}:  sup = 0.072\n",
      "{No, Larceny}:  sup = 0.081\n",
      "{Part One, No}:  sup = 0.177\n",
      "{Part One, Larceny}:  sup = 0.081\n",
      "{Thursday, No}:  sup = 0.147\n",
      "{Other, Part Two}:  sup = 0.053\n",
      "{No, Roxbury}:  sup = 0.156\n",
      "{Part Two, Roxbury}:  sup = 0.053\n",
      "{Part Three, Mattapan}:  sup = 0.064\n",
      "{No, Jul}:  sup = 0.098\n",
      "{Monday, No}:  sup = 0.141\n",
      "{No, Morning}:  sup = 0.294\n",
      "{Part Two, Morning}:  sup = 0.082\n",
      "{South Boston, No}:  sup = 0.074\n",
      "{Part Three, Evening}:  sup = 0.112\n",
      "{No, Downtown}:  sup = 0.152\n",
      "{Part Three, Downtown}:  sup = 0.073\n",
      "{Medical Assistance, No}:  sup = 0.083\n",
      "{Part Three, Medical Assistance}:  sup = 0.083\n",
      "{No, Brighton}:  sup = 0.063\n",
      "{No, Evening}:  sup = 0.229\n",
      "{Part Two, Evening}:  sup = 0.074\n",
      "{No, Mattapan}:  sup = 0.115\n",
      "{Other, No}:  sup = 0.06\n",
      "{Part Three, Friday}:  sup = 0.079\n",
      "{Part Three, Night}:  sup = 0.13\n",
      "{Part Three, No}:  sup = 0.518\n",
      "{Part Three, South End}:  sup = 0.056\n",
      "{Aug, No}:  sup = 0.093\n",
      "{No, Friday}:  sup = 0.153\n",
      "{Night, No}:  sup = 0.251\n",
      "{Part Two, Night}:  sup = 0.074\n",
      "{Part Two, No}:  sup = 0.298\n",
      "{No, Simple Assault}:  sup = 0.052\n",
      "{Part Two, Simple Assault}:  sup = 0.052\n",
      "{South End, No}:  sup = 0.126\n",
      "{Part Three, Saturday, No}:  sup = 0.074\n",
      "{Part Three, Sunday, No}:  sup = 0.066\n",
      "{Part Three, Monday, No}:  sup = 0.073\n",
      "{Part Three, Thursday, No}:  sup = 0.076\n",
      "{Wednesday, Part Three, No}:  sup = 0.076\n",
      "{Part Three, No, Noon}:  sup = 0.113\n",
      "{Part Two, No, Noon}:  sup = 0.068\n",
      "{Part Three, Tuesday, No}:  sup = 0.074\n",
      "{Part Three, No, Morning}:  sup = 0.163\n",
      "{Part Three, No, Jul}:  sup = 0.05\n",
      "{Part Three, No, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{Part Three, No, Investigate Person}:  sup = 0.062\n",
      "{Part Three, No, Roxbury}:  sup = 0.078\n",
      "{Part Three, No, Dorchester}:  sup = 0.072\n",
      "{Part One, No, Larceny}:  sup = 0.081\n",
      "{Other, No, Part Two}:  sup = 0.053\n",
      "{Part Two, No, Roxbury}:  sup = 0.053\n",
      "{Part Three, No, Mattapan}:  sup = 0.064\n",
      "{Part Two, No, Morning}:  sup = 0.082\n",
      "{Part Three, Medical Assistance, No}:  sup = 0.083\n",
      "{Part Three, No, Downtown}:  sup = 0.072\n",
      "{Part Three, No, Evening}:  sup = 0.112\n",
      "{Part Two, No, Evening}:  sup = 0.074\n",
      "{Part Three, South End, No}:  sup = 0.055\n",
      "{Part Three, No, Night}:  sup = 0.13\n",
      "{Part Three, No, Friday}:  sup = 0.079\n",
      "{Part Two, No, Simple Assault}:  sup = 0.052\n",
      "{Night, No, Part Two}:  sup = 0.074\n"
     ]
    }
   ],
   "source": [
    "# Frequent itemsets with support 5%\n",
    "F_apr, support_data_apr = apriori(df[:200000], min_support=0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Feb} ---> {No}:  conf = 0.997, sup = 0.069\n",
      "{Nov} ---> {No}:  conf = 0.997, sup = 0.078\n",
      "{Jan} ---> {No}:  conf = 0.997, sup = 0.078\n",
      "{Oct} ---> {No}:  conf = 0.995, sup = 0.086\n",
      "{Saturday} ---> {No}:  conf = 0.995, sup = 0.14\n",
      "{Apr} ---> {No}:  conf = 0.998, sup = 0.078\n",
      "{Sep} ---> {No}:  conf = 0.996, sup = 0.087\n",
      "{Mar} ---> {No}:  conf = 0.999, sup = 0.078\n",
      "{May} ---> {No}:  conf = 0.997, sup = 0.088\n",
      "{Sunday} ---> {No}:  conf = 0.995, sup = 0.125\n",
      "{Jun} ---> {No}:  conf = 0.996, sup = 0.087\n",
      "{Dec} ---> {No}:  conf = 0.996, sup = 0.076\n",
      "{Wednesday} ---> {No}:  conf = 0.998, sup = 0.148\n",
      "{Noon} ---> {No}:  conf = 0.997, sup = 0.223\n",
      "{Tuesday} ---> {No}:  conf = 0.998, sup = 0.144\n",
      "{Motor Vehicle Accident Response} ---> {No}:  conf = 1.0, sup = 0.117\n",
      "{Motor Vehicle Accident Response} ---> {Part Three}:  conf = 1.0, sup = 0.117\n",
      "{Investigate Person} ---> {No}:  conf = 0.999, sup = 0.062\n",
      "{Investigate Person} ---> {Part Three}:  conf = 1.0, sup = 0.062\n",
      "{Jamaice Plain} ---> {No}:  conf = 0.996, sup = 0.054\n",
      "{Hyde Park} ---> {No}:  conf = 0.997, sup = 0.056\n",
      "{Dorchester} ---> {No}:  conf = 0.996, sup = 0.131\n",
      "{Larceny} ---> {No}:  conf = 1.0, sup = 0.081\n",
      "{Part One} ---> {No}:  conf = 0.989, sup = 0.177\n",
      "{Larceny} ---> {Part One}:  conf = 1.0, sup = 0.081\n",
      "{Thursday} ---> {No}:  conf = 0.998, sup = 0.147\n",
      "{Roxbury} ---> {No}:  conf = 0.993, sup = 0.156\n",
      "{Jul} ---> {No}:  conf = 0.996, sup = 0.098\n",
      "{Monday} ---> {No}:  conf = 0.997, sup = 0.141\n",
      "{Morning} ---> {No}:  conf = 0.999, sup = 0.294\n",
      "{South Boston} ---> {No}:  conf = 0.998, sup = 0.074\n",
      "{Downtown} ---> {No}:  conf = 0.999, sup = 0.152\n",
      "{Medical Assistance} ---> {No}:  conf = 0.999, sup = 0.083\n",
      "{Medical Assistance} ---> {Part Three}:  conf = 1.0, sup = 0.083\n",
      "{Brighton} ---> {No}:  conf = 0.999, sup = 0.063\n",
      "{Evening} ---> {No}:  conf = 0.997, sup = 0.229\n",
      "{Mattapan} ---> {No}:  conf = 0.994, sup = 0.115\n",
      "{Other} ---> {No}:  conf = 0.999, sup = 0.06\n",
      "{Part Three} ---> {No}:  conf = 0.999, sup = 0.518\n",
      "{Aug} ---> {No}:  conf = 0.997, sup = 0.093\n",
      "{Friday} ---> {No}:  conf = 0.997, sup = 0.153\n",
      "{Night} ---> {No}:  conf = 0.993, sup = 0.251\n",
      "{Part Two} ---> {No}:  conf = 0.998, sup = 0.298\n",
      "{Simple Assault} ---> {No}:  conf = 1.0, sup = 0.052\n",
      "{Simple Assault} ---> {Part Two}:  conf = 1.0, sup = 0.052\n",
      "{South End} ---> {No}:  conf = 0.998, sup = 0.126\n",
      "{Part Three, Saturday} ---> {No}:  conf = 0.998, sup = 0.074\n",
      "{Part Three, Sunday} ---> {No}:  conf = 0.998, sup = 0.066\n",
      "{Part Three, Monday} ---> {No}:  conf = 0.999, sup = 0.073\n",
      "{Part Three, Thursday} ---> {No}:  conf = 0.999, sup = 0.076\n",
      "{Wednesday, Part Three} ---> {No}:  conf = 0.999, sup = 0.076\n",
      "{Part Three, Noon} ---> {No}:  conf = 0.999, sup = 0.113\n",
      "{Part Two, Noon} ---> {No}:  conf = 0.998, sup = 0.068\n",
      "{Part Three, Tuesday} ---> {No}:  conf = 0.999, sup = 0.074\n",
      "{Part Three, Morning} ---> {No}:  conf = 0.999, sup = 0.163\n",
      "{Part Three, Jul} ---> {No}:  conf = 0.998, sup = 0.05\n",
      "{No, Motor Vehicle Accident Response} ---> {Part Three}:  conf = 1.0, sup = 0.117\n",
      "{Part Three, Motor Vehicle Accident Response} ---> {No}:  conf = 1.0, sup = 0.117\n",
      "{Motor Vehicle Accident Response} ---> {Part Three, No}:  conf = 1.0, sup = 0.117\n",
      "{No, Investigate Person} ---> {Part Three}:  conf = 1.0, sup = 0.062\n",
      "{Part Three, Investigate Person} ---> {No}:  conf = 0.999, sup = 0.062\n",
      "{Investigate Person} ---> {Part Three, No}:  conf = 0.999, sup = 0.062\n",
      "{Part Three, Roxbury} ---> {No}:  conf = 0.997, sup = 0.078\n",
      "{Part Three, Dorchester} ---> {No}:  conf = 0.999, sup = 0.072\n",
      "{No, Larceny} ---> {Part One}:  conf = 1.0, sup = 0.081\n",
      "{Part One, Larceny} ---> {No}:  conf = 1.0, sup = 0.081\n",
      "{Larceny} ---> {Part One, No}:  conf = 1.0, sup = 0.081\n",
      "{Other, Part Two} ---> {No}:  conf = 0.999, sup = 0.053\n",
      "{Part Two, Roxbury} ---> {No}:  conf = 0.995, sup = 0.053\n",
      "{Part Three, Mattapan} ---> {No}:  conf = 0.998, sup = 0.064\n",
      "{Part Two, Morning} ---> {No}:  conf = 0.999, sup = 0.082\n",
      "{Medical Assistance, No} ---> {Part Three}:  conf = 1.0, sup = 0.083\n",
      "{Part Three, Medical Assistance} ---> {No}:  conf = 0.999, sup = 0.083\n",
      "{Medical Assistance} ---> {Part Three, No}:  conf = 0.999, sup = 0.083\n",
      "{Part Three, Downtown} ---> {No}:  conf = 0.999, sup = 0.072\n",
      "{Part Three, Evening} ---> {No}:  conf = 0.999, sup = 0.112\n",
      "{Part Two, Evening} ---> {No}:  conf = 0.999, sup = 0.074\n",
      "{Part Three, South End} ---> {No}:  conf = 0.999, sup = 0.055\n",
      "{Part Three, Night} ---> {No}:  conf = 0.998, sup = 0.13\n",
      "{Part Three, Friday} ---> {No}:  conf = 0.998, sup = 0.079\n",
      "{No, Simple Assault} ---> {Part Two}:  conf = 1.0, sup = 0.052\n",
      "{Part Two, Simple Assault} ---> {No}:  conf = 1.0, sup = 0.052\n",
      "{Simple Assault} ---> {Part Two, No}:  conf = 1.0, sup = 0.052\n",
      "{Night, Part Two} ---> {No}:  conf = 0.996, sup = 0.074\n"
     ]
    }
   ],
   "source": [
    "# Association rules with confidence 40%\n",
    "H_apr = generate_rules(F_apr, support_data_apr, min_confidence=0.9, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2014 Reid Johnson\n",
    "#\n",
    "# Modified from:\n",
    "# Eric Naeseth <eric@naeseth.com>\n",
    "# (https://github.com/enaeseth/python-fp-growth/blob/master/fp_growth.py)\n",
    "#\n",
    "# A Python implementation of the FP-growth algorithm.\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "#from itertools import imap\n",
    "\n",
    "__author__ = 'Eric Naeseth <eric@naeseth.com>'\n",
    "__copyright__ = 'Copyright © 2009 Eric Naeseth'\n",
    "__license__ = 'MIT License'\n",
    "\n",
    "def fpgrowth(dataset, min_support=0.5, include_support=True, verbose=False):\n",
    "    \"\"\"Implements the FP-growth algorithm.\n",
    "\n",
    "    The `dataset` parameter can be any iterable of iterables of items.\n",
    "    `min_support` should be an integer specifying the minimum number of\n",
    "    occurrences of an itemset for it to be accepted.\n",
    "\n",
    "    Each item must be hashable (i.e., it must be valid as a member of a\n",
    "    dictionary or a set).\n",
    "\n",
    "    If `include_support` is true, yield (itemset, support) pairs instead of\n",
    "    just the itemsets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    include_support : bool\n",
    "        Include support in output (default=False).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. Han, J. Pei, Y. Yin, \"Mining Frequent Patterns without Candidate \n",
    "           Generation,\" 2000.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    F = []\n",
    "    support_data = {}\n",
    "    for k,v in find_frequent_itemsets(dataset, min_support=min_support, include_support=include_support, verbose=verbose):\n",
    "        F.append(frozenset(k))\n",
    "        support_data[frozenset(k)] = v\n",
    "\n",
    "    # Create one array with subarrays that hold all transactions of equal length.\n",
    "    def bucket_list(nested_list, sort=True):\n",
    "        bucket = defaultdict(list)\n",
    "        for sublist in nested_list:\n",
    "            bucket[len(sublist)].append(sublist)\n",
    "        return [v for k,v in sorted(bucket.items())] if sort else bucket.values()\n",
    "\n",
    "    F = bucket_list(F)\n",
    "    \n",
    "    return F, support_data\n",
    "\n",
    "def find_frequent_itemsets(dataset, min_support, include_support=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Find frequent itemsets in the given transactions using FP-growth. This\n",
    "    function returns a generator instead of an eagerly-populated list of items.\n",
    "\n",
    "    The `dataset` parameter can be any iterable of iterables of items.\n",
    "    `min_support` should be an integer specifying the minimum number of\n",
    "    occurrences of an itemset for it to be accepted.\n",
    "\n",
    "    Each item must be hashable (i.e., it must be valid as a member of a\n",
    "    dictionary or a set).\n",
    "\n",
    "    If `include_support` is true, yield (itemset, support) pairs instead of\n",
    "    just the itemsets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    include_support : bool\n",
    "        Include support in output (default=False).\n",
    "\n",
    "    \"\"\"\n",
    "    items = defaultdict(lambda: 0) # mapping from items to their supports\n",
    "    processed_transactions = []\n",
    "\n",
    "    # Load the passed-in transactions and count the support that individual\n",
    "    # items have.\n",
    "    for transaction in dataset:\n",
    "        processed = []\n",
    "        for item in transaction:\n",
    "            items[item] += 1\n",
    "            processed.append(item)\n",
    "        processed_transactions.append(processed)\n",
    "\n",
    "    # Remove infrequent items from the item support dictionary.\n",
    "    items = dict((item, support) for item, support in items.items()\n",
    "        if support >= min_support)\n",
    "\n",
    "    # Build our FP-tree. Before any transactions can be added to the tree, they\n",
    "    # must be stripped of infrequent items and their surviving items must be\n",
    "    # sorted in decreasing order of frequency.\n",
    "    def clean_transaction(transaction):\n",
    "        #transaction = filter(lambda v: v in items, transaction)\n",
    "        transaction.sort(key=lambda v: items[v], reverse=True)\n",
    "        return transaction\n",
    "\n",
    "    master = FPTree()\n",
    "    for transaction in map(clean_transaction, processed_transactions):\n",
    "        master.add(transaction)\n",
    "\n",
    "    support_data = {}\n",
    "    def find_with_suffix(tree, suffix):\n",
    "        for item, nodes in tree.items():\n",
    "            support = float(sum(n.count for n in nodes)) / len(dataset)\n",
    "            if support >= min_support and item not in suffix:\n",
    "                # New winner!\n",
    "                found_set = [item] + suffix\n",
    "                support_data[frozenset(found_set)] = support\n",
    "                yield (found_set, support) if include_support else found_set\n",
    "\n",
    "                # Build a conditional tree and recursively search for frequent\n",
    "                # itemsets within it.\n",
    "                cond_tree = conditional_tree_from_paths(tree.prefix_paths(item),\n",
    "                    min_support)\n",
    "                for s in find_with_suffix(cond_tree, found_set):\n",
    "                    yield s # pass along the good news to our caller\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the frequent itemsets.\n",
    "        for itemset, support in find_with_suffix(master, []):\n",
    "            print(\"\" \\\n",
    "                + \"{\" \\\n",
    "                + \"\".join(str(i) + \", \" for i in iter(itemset)).rstrip(', ') \\\n",
    "                + \"}\" \\\n",
    "                + \":  sup = \" + str(round(support_data[frozenset(itemset)], 3)))\n",
    "\n",
    "    # Search for frequent itemsets, and yield the results we find.\n",
    "    for itemset in find_with_suffix(master, []):\n",
    "        yield itemset\n",
    "\n",
    "class FPTree(object):\n",
    "    \"\"\"\n",
    "    An FP tree.\n",
    "\n",
    "    This object may only store transaction items that are hashable (i.e., all\n",
    "    items must be valid as dictionary keys or set members).\n",
    "    \"\"\"\n",
    "\n",
    "    Route = namedtuple('Route', 'head tail')\n",
    "\n",
    "    def __init__(self):\n",
    "        # The root node of the tree.\n",
    "        self._root = FPNode(self, None, None)\n",
    "\n",
    "        # A dictionary mapping items to the head and tail of a path of\n",
    "        # \"neighbors\" that will hit every node containing that item.\n",
    "        self._routes = {}\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        \"\"\"The root node of the tree.\"\"\"\n",
    "        return self._root\n",
    "\n",
    "    def add(self, transaction):\n",
    "        \"\"\"\n",
    "        Adds a transaction to the tree.\n",
    "        \"\"\"\n",
    "\n",
    "        point = self._root\n",
    "\n",
    "        for item in transaction:\n",
    "            next_point = point.search(item)\n",
    "            if next_point:\n",
    "                # There is already a node in this tree for the current\n",
    "                # transaction item; reuse it.\n",
    "                next_point.increment()\n",
    "            else:\n",
    "                # Create a new point and add it as a child of the point we're\n",
    "                # currently looking at.\n",
    "                next_point = FPNode(self, item)\n",
    "                point.add(next_point)\n",
    "\n",
    "                # Update the route of nodes that contain this item to include\n",
    "                # our new node.\n",
    "                self._update_route(next_point)\n",
    "\n",
    "            point = next_point\n",
    "\n",
    "    def _update_route(self, point):\n",
    "        \"\"\"Add the given node to the route through all nodes for its item.\"\"\"\n",
    "        assert self is point.tree\n",
    "\n",
    "        try:\n",
    "            route = self._routes[point.item]\n",
    "            route[1].neighbor = point # route[1] is the tail\n",
    "            self._routes[point.item] = self.Route(route[0], point)\n",
    "        except KeyError:\n",
    "            # First node for this item; start a new route.\n",
    "            self._routes[point.item] = self.Route(point, point)\n",
    "\n",
    "    def items(self):\n",
    "        \"\"\"\n",
    "        Generate one 2-tuples for each item represented in the tree. The first\n",
    "        element of the tuple is the item itself, and the second element is a\n",
    "        generator that will yield the nodes in the tree that belong to the item.\n",
    "        \"\"\"\n",
    "        for item in self._routes.keys():\n",
    "            yield (item, self.nodes(item))\n",
    "\n",
    "            \n",
    "    def nodes(self, item):\n",
    "        \"\"\"\n",
    "        Generates the sequence of nodes that contain the given item.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            node = self._routes[item][0]\n",
    "        except KeyError:\n",
    "            return\n",
    "\n",
    "        while node:\n",
    "            yield node\n",
    "            node = node.neighbor\n",
    "\n",
    "    def prefix_paths(self, item):\n",
    "        \"\"\"Generates the prefix paths that end with the given item.\"\"\"\n",
    "\n",
    "        def collect_path(node):\n",
    "            path = []\n",
    "            while node and not node.root:\n",
    "                path.append(node)\n",
    "                node = node.parent\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        return (collect_path(node) for node in self.nodes(item))\n",
    "\n",
    "    def inspect(self):\n",
    "        print(\"Tree:\")\n",
    "        self.root.inspect(1)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Routes:\")\n",
    "        for item, nodes in self.items():\n",
    "            print(\"  %r\" % item)\n",
    "            for node in nodes:\n",
    "                print(\"    %r\" % node)\n",
    "\n",
    "    def _removed(self, node):\n",
    "        \"\"\"Called when `node` is removed from the tree; performs cleanup.\"\"\"\n",
    "\n",
    "        head, tail = self._routes[node.item]\n",
    "        if node is head:\n",
    "            if node is tail or not node.neighbor:\n",
    "                # It was the sole node.\n",
    "                del self._routes[node.item]\n",
    "            else:\n",
    "                self._routes[node.item] = self.Route(node.neighbor, tail)\n",
    "        else:\n",
    "            for n in self.nodes(node.item):\n",
    "                if n.neighbor is node:\n",
    "                    n.neighbor = node.neighbor # skip over\n",
    "                    if node is tail:\n",
    "                        self._routes[node.item] = self.Route(head, n)\n",
    "                    break\n",
    "\n",
    "def conditional_tree_from_paths(paths, min_support):\n",
    "    \"\"\"Builds a conditional FP-tree from the given prefix paths.\"\"\"\n",
    "    tree = FPTree()\n",
    "    condition_item = None\n",
    "    items = set()\n",
    "\n",
    "    # Import the nodes in the paths into the new tree. Only the counts of the\n",
    "    # leaf notes matter; the remaining counts will be reconstructed from the\n",
    "    # leaf counts.\n",
    "    for path in paths:\n",
    "        if condition_item is None:\n",
    "            condition_item = path[-1].item\n",
    "\n",
    "        point = tree.root\n",
    "        for node in path:\n",
    "            next_point = point.search(node.item)\n",
    "            if not next_point:\n",
    "                # Add a new node to the tree.\n",
    "                items.add(node.item)\n",
    "                count = node.count if node.item == condition_item else 0\n",
    "                next_point = FPNode(tree, node.item, count)\n",
    "                point.add(next_point)\n",
    "                tree._update_route(next_point)\n",
    "            point = next_point\n",
    "\n",
    "    assert condition_item is not None\n",
    "\n",
    "    # Calculate the counts of the non-leaf nodes.\n",
    "    for path in tree.prefix_paths(condition_item):\n",
    "        count = path[-1].count\n",
    "        for node in reversed(path[:-1]):\n",
    "            node._count += count\n",
    "\n",
    "    # Eliminate the nodes for any items that are no longer frequent.\n",
    "    for item in items:\n",
    "        support = sum(n.count for n in tree.nodes(item))\n",
    "        if support < min_support:\n",
    "            # Doesn't make the cut anymore\n",
    "            for node in tree.nodes(item):\n",
    "                if node.parent is not None:\n",
    "                    node.parent.remove(node)\n",
    "\n",
    "    # Finally, remove the nodes corresponding to the item for which this\n",
    "    # conditional tree was generated.\n",
    "    for node in tree.nodes(condition_item):\n",
    "        if node.parent is not None: # the node might already be an orphan\n",
    "            node.parent.remove(node)\n",
    "\n",
    "    return tree\n",
    "\n",
    "class FPNode(object):\n",
    "    \"\"\"A node in an FP tree.\"\"\"\n",
    "\n",
    "    def __init__(self, tree, item, count=1):\n",
    "        self._tree = tree\n",
    "        self._item = item\n",
    "        self._count = count\n",
    "        self._parent = None\n",
    "        self._children = {}\n",
    "        self._neighbor = None\n",
    "\n",
    "    def add(self, child):\n",
    "        \"\"\"Adds the given FPNode `child` as a child of this node.\"\"\"\n",
    "\n",
    "        if not isinstance(child, FPNode):\n",
    "            raise TypeError(\"Can only add other FPNodes as children\")\n",
    "\n",
    "        if not child.item in self._children:\n",
    "            self._children[child.item] = child\n",
    "            child.parent = self\n",
    "\n",
    "    def search(self, item):\n",
    "        \"\"\"\n",
    "        Checks to see if this node contains a child node for the given item.\n",
    "        If so, that node is returned; otherwise, `None` is returned.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            return self._children[item]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def remove(self, child):\n",
    "        try:\n",
    "            if self._children[child.item] is child:\n",
    "                del self._children[child.item]\n",
    "                child.parent = None\n",
    "                self._tree._removed(child)\n",
    "                for sub_child in child.children:\n",
    "                    try:\n",
    "                        # Merger case: we already have a child for that item, so\n",
    "                        # add the sub-child's count to our child's count.\n",
    "                        self._children[sub_child.item]._count += sub_child.count\n",
    "                        sub_child.parent = None # it's an orphan now\n",
    "                    except KeyError:\n",
    "                        # Turns out we don't actually have a child, so just add\n",
    "                        # the sub-child as our own child.\n",
    "                        self.add(sub_child)\n",
    "                child._children = {}\n",
    "            else:\n",
    "                raise ValueError(\"that node is not a child of this node\")\n",
    "        except KeyError:\n",
    "            raise ValueError(\"that node is not a child of this node\")\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self._children\n",
    "\n",
    "    @property\n",
    "    def tree(self):\n",
    "        \"\"\"The tree in which this node appears.\"\"\"\n",
    "        return self._tree\n",
    "\n",
    "    @property\n",
    "    def item(self):\n",
    "        \"\"\"The item contained in this node.\"\"\"\n",
    "        return self._item\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        \"\"\"The count associated with this node's item.\"\"\"\n",
    "        return self._count\n",
    "\n",
    "    def increment(self):\n",
    "        \"\"\"Increments the count associated with this node's item.\"\"\"\n",
    "        if self._count is None:\n",
    "            raise ValueError(\"Root nodes have no associated count.\")\n",
    "        self._count += 1\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        \"\"\"True if this node is the root of a tree; false if otherwise.\"\"\"\n",
    "        return self._item is None and self._count is None\n",
    "\n",
    "    @property\n",
    "    def leaf(self):\n",
    "        \"\"\"True if this node is a leaf in the tree; false if otherwise.\"\"\"\n",
    "        return len(self._children) == 0\n",
    "\n",
    "    def parent():\n",
    "        doc = \"The node's parent.\"\n",
    "        def fget(self):\n",
    "            return self._parent\n",
    "        def fset(self, value):\n",
    "            if value is not None and not isinstance(value, FPNode):\n",
    "                raise TypeError(\"A node must have an FPNode as a parent.\")\n",
    "            if value and value.tree is not self.tree:\n",
    "                raise ValueError(\"Cannot have a parent from another tree.\")\n",
    "            self._parent = value\n",
    "        return locals()\n",
    "    parent = property(**parent())\n",
    "\n",
    "    def neighbor():\n",
    "        doc = \"\"\"\n",
    "        The node's neighbor; the one with the same value that is \"to the right\"\n",
    "        of it in the tree.\n",
    "        \"\"\"\n",
    "        def fget(self):\n",
    "            return self._neighbor\n",
    "        def fset(self, value):\n",
    "            if value is not None and not isinstance(value, FPNode):\n",
    "                raise TypeError(\"A node must have an FPNode as a neighbor.\")\n",
    "            if value and value.tree is not self.tree:\n",
    "                raise ValueError(\"Cannot have a neighbor from another tree.\")\n",
    "            self._neighbor = value\n",
    "        return locals()\n",
    "    neighbor = property(**neighbor())\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        \"\"\"The nodes that are children of this node.\"\"\"\n",
    "        return tuple(self._children.values())\n",
    "        \n",
    "    def inspect(self, depth=0):\n",
    "        print(('  ' * depth) + repr(self))\n",
    "        for child in self.children:\n",
    "            child.inspect(depth + 1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.root:\n",
    "            return \"<%s (root)>\" % type(self).__name__\n",
    "        return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)\n",
    "\n",
    "def rules_from_conseq(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Generates a set of candidate rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "    m = len(H[0])\n",
    "    if m == 1:\n",
    "        Hmp1 = calc_confidence(freq_set, H, support_data, rules, min_confidence, verbose)\n",
    "    if (len(freq_set) > (m+1)):\n",
    "        Hmp1 = apriori_gen(H, m+1) # generate candidate itemsets\n",
    "        Hmp1 = calc_confidence(freq_set, Hmp1,  support_data, rules, min_confidence, verbose)\n",
    "        if len(Hmp1) > 1:\n",
    "            # If there are candidate rules above the minimum confidence \n",
    "            # threshold, recurse on the list of these candidate rules.\n",
    "            rules_from_conseq(freq_set, Hmp1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "def calc_confidence(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Evaluates the generated rules.\n",
    "\n",
    "    One measurement for quantifying the goodness of association rules is \n",
    "    confidence. The confidence for a rule 'P implies H' (P -> H) is defined as \n",
    "    the support for P and H divided by the support for P \n",
    "    (support (P|H) / support(P)), where the | symbol denotes the set union \n",
    "    (thus P|H means all the items in set P or in set H).\n",
    "\n",
    "    To calculate the confidence, we iterate through the frequent itemsets and \n",
    "    associated support data. For each frequent itemset, we divide the support \n",
    "    of the itemset by the support of the antecedent (left-hand-side of the \n",
    "    rule).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pruned_H : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    pruned_H = [] # list of candidate rules above the minimum confidence threshold\n",
    "    for conseq in H: # iterate over the frequent itemsets\n",
    "        conf = support_data[freq_set] / support_data[freq_set - conseq]\n",
    "        if conf >= min_confidence:\n",
    "            rules.append((freq_set - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(freq_set-conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \" ---> \" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  conf = \" + str(round(conf, 3)) \\\n",
    "                    + \", sup = \" + str(round(support_data[freq_set], 3)))\n",
    "\n",
    "    return pruned_H\n",
    "\n",
    "def generate_rules(F, support_data, min_confidence=0.5, verbose=True):\n",
    "    \"\"\"Generates a set of candidate rules from a list of frequent itemsets.\n",
    "\n",
    "    For each frequent itemset, we calculate the confidence of using a\n",
    "    particular item as the rule consequent (right-hand-side of the rule). By \n",
    "    testing and merging the remaining rules, we recursively create a list of \n",
    "    pruned rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : list\n",
    "        A list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The corresponding support data for the frequent itemsets (L).\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rules : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(F)):\n",
    "        for freq_set in F[i]:\n",
    "            H1 = [frozenset([item]) for item in freq_set]\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "            else:\n",
    "                calc_confidence(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{No}:  sup = 0.997\n",
      "{Part Two}:  sup = 0.305\n",
      "{No, Part Two}:  sup = 0.304\n",
      "{Night}:  sup = 0.254\n",
      "{No, Night}:  sup = 0.252\n",
      "{Part Three, Night}:  sup = 0.127\n",
      "{No, Part Three, Night}:  sup = 0.127\n",
      "{Friday}:  sup = 0.152\n",
      "{No, Friday}:  sup = 0.152\n",
      "{South End}:  sup = 0.129\n",
      "{No, South End}:  sup = 0.129\n",
      "{Part Three}:  sup = 0.502\n",
      "{No, Part Three}:  sup = 0.502\n",
      "{Evening}:  sup = 0.233\n",
      "{No, Evening}:  sup = 0.232\n",
      "{Part Three, Evening}:  sup = 0.109\n",
      "{No, Part Three, Evening}:  sup = 0.109\n",
      "{Mattapan}:  sup = 0.113\n",
      "{No, Mattapan}:  sup = 0.112\n",
      "{Downtown}:  sup = 0.152\n",
      "{No, Downtown}:  sup = 0.152\n",
      "{Morning}:  sup = 0.292\n",
      "{No, Morning}:  sup = 0.291\n",
      "{Part Three, Morning}:  sup = 0.157\n",
      "{No, Part Three, Morning}:  sup = 0.157\n",
      "{Monday}:  sup = 0.143\n",
      "{No, Monday}:  sup = 0.143\n",
      "{Jul}:  sup = 0.106\n",
      "{No, Jul}:  sup = 0.106\n",
      "{Roxbury}:  sup = 0.158\n",
      "{No, Roxbury}:  sup = 0.157\n",
      "{Part One}:  sup = 0.189\n",
      "{No, Part One}:  sup = 0.187\n",
      "{Thursday}:  sup = 0.146\n",
      "{No, Thursday}:  sup = 0.146\n",
      "{Dorchester}:  sup = 0.135\n",
      "{No, Dorchester}:  sup = 0.134\n",
      "{Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{No, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{Part Three, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{No, Part Three, Motor Vehicle Accident Response}:  sup = 0.117\n",
      "{Tuesday}:  sup = 0.145\n",
      "{No, Tuesday}:  sup = 0.144\n",
      "{Noon}:  sup = 0.222\n",
      "{No, Noon}:  sup = 0.221\n",
      "{Part Three, Noon}:  sup = 0.109\n",
      "{No, Part Three, Noon}:  sup = 0.109\n",
      "{Wednesday}:  sup = 0.147\n",
      "{No, Wednesday}:  sup = 0.147\n",
      "{Sunday}:  sup = 0.126\n",
      "{No, Sunday}:  sup = 0.126\n",
      "{Saturday}:  sup = 0.14\n",
      "{No, Saturday}:  sup = 0.14\n"
     ]
    }
   ],
   "source": [
    "F_fp, support_data_fp = fpgrowth(df, min_support=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Part Two} ---> {No}:  conf = 0.998, sup = 0.304\n",
      "{Night} ---> {No}:  conf = 0.993, sup = 0.252\n",
      "{Night} ---> {Part Three}:  conf = 0.501, sup = 0.127\n",
      "{Friday} ---> {No}:  conf = 0.997, sup = 0.152\n",
      "{South End} ---> {No}:  conf = 0.999, sup = 0.129\n",
      "{No} ---> {Part Three}:  conf = 0.503, sup = 0.502\n",
      "{Part Three} ---> {No}:  conf = 0.999, sup = 0.502\n",
      "{Evening} ---> {No}:  conf = 0.997, sup = 0.232\n",
      "{Evening} ---> {Part Three}:  conf = 0.467, sup = 0.109\n",
      "{Mattapan} ---> {No}:  conf = 0.994, sup = 0.112\n",
      "{Downtown} ---> {No}:  conf = 0.999, sup = 0.152\n",
      "{Morning} ---> {No}:  conf = 0.999, sup = 0.291\n",
      "{Morning} ---> {Part Three}:  conf = 0.54, sup = 0.157\n",
      "{Monday} ---> {No}:  conf = 0.997, sup = 0.143\n",
      "{Jul} ---> {No}:  conf = 0.996, sup = 0.106\n",
      "{Roxbury} ---> {No}:  conf = 0.993, sup = 0.157\n",
      "{Part One} ---> {No}:  conf = 0.989, sup = 0.187\n",
      "{Thursday} ---> {No}:  conf = 0.997, sup = 0.146\n",
      "{Dorchester} ---> {No}:  conf = 0.996, sup = 0.134\n",
      "{Motor Vehicle Accident Response} ---> {No}:  conf = 1.0, sup = 0.117\n",
      "{Motor Vehicle Accident Response} ---> {Part Three}:  conf = 1.0, sup = 0.117\n",
      "{Tuesday} ---> {No}:  conf = 0.997, sup = 0.144\n",
      "{Noon} ---> {No}:  conf = 0.997, sup = 0.221\n",
      "{Noon} ---> {Part Three}:  conf = 0.492, sup = 0.109\n",
      "{Wednesday} ---> {No}:  conf = 0.997, sup = 0.147\n",
      "{Sunday} ---> {No}:  conf = 0.996, sup = 0.126\n",
      "{Saturday} ---> {No}:  conf = 0.995, sup = 0.14\n",
      "{Night, No} ---> {Part Three}:  conf = 0.503, sup = 0.127\n",
      "{Part Three, Night} ---> {No}:  conf = 0.998, sup = 0.127\n",
      "{Night} ---> {Part Three, No}:  conf = 0.499, sup = 0.127\n",
      "{No, Evening} ---> {Part Three}:  conf = 0.467, sup = 0.109\n",
      "{Part Three, Evening} ---> {No}:  conf = 0.999, sup = 0.109\n",
      "{Evening} ---> {Part Three, No}:  conf = 0.466, sup = 0.109\n",
      "{No, Morning} ---> {Part Three}:  conf = 0.54, sup = 0.157\n",
      "{Part Three, Morning} ---> {No}:  conf = 1.0, sup = 0.157\n",
      "{Morning} ---> {Part Three, No}:  conf = 0.54, sup = 0.157\n",
      "{No, Motor Vehicle Accident Response} ---> {Part Three}:  conf = 1.0, sup = 0.117\n",
      "{Part Three, Motor Vehicle Accident Response} ---> {No}:  conf = 1.0, sup = 0.117\n",
      "{Motor Vehicle Accident Response} ---> {Part Three, No}:  conf = 1.0, sup = 0.117\n",
      "{No, Noon} ---> {Part Three}:  conf = 0.493, sup = 0.109\n",
      "{Part Three, Noon} ---> {No}:  conf = 0.999, sup = 0.109\n",
      "{Noon} ---> {Part Three, No}:  conf = 0.491, sup = 0.109\n"
     ]
    }
   ],
   "source": [
    "H_fp = generate_rules(F_fp, support_data_fp, min_confidence=0.4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
